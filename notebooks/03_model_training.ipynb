{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for Rainfall Forecasting\n",
    "\n",
    "This notebook implements and evaluates various machine learning models for rainfall forecasting in Selangor.\n",
    "\n",
    "## Objectives:\n",
    "- Train and compare multiple models (ARIMA, ANN, KNN, RF, XGBoost)\n",
    "- Perform hyperparameter tuning\n",
    "- Evaluate model performance using MAE, MSE, RMSE, R-squared\n",
    "- Select the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "# Models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load engineered features\n",
    "df = pd.read_csv(\"../data/processed/engineered_features.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(['Date', 'Precipitation_mm'], axis=1)\n",
    "y = df['Precipitation_mm']\n",
    "\n",
    "# Time-based train-test split (80-20 split)\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "dates_test = df['Date'].iloc[split_idx:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Date range - Train: {df['Date'].iloc[0]} to {df['Date'].iloc[split_idx-1]}\")\n",
    "print(f\"Date range - Test: {df['Date'].iloc[split_idx]} to {df['Date'].iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate model performance and return metrics.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'MSE': mean_squared_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_arima(y_train, p_range=[0,1,2], d_range=[0,1], q_range=[0,1]):\n",
    "    \"\"\"\n",
    "    Train ARIMA model with grid search for best parameters.\n",
    "    \"\"\"\n",
    "    best_aic = float('inf')\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "    \n",
    "    for p in p_range:\n",
    "        for d in d_range:\n",
    "            for q in q_range:\n",
    "                try:\n",
    "                    model = ARIMA(y_train, order=(p,d,q))\n",
    "                    results = model.fit()\n",
    "                    \n",
    "                    if results.aic < best_aic:\n",
    "                        best_aic = results.aic\n",
    "                        best_order = (p,d,q)\n",
    "                        best_model = results\n",
    "                        \n",
    "                    print(f\"ARIMA{p,d,q} - AIC: {results.aic:.2f}\")\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "    print(f\"\\nBest ARIMA model: {best_order} with AIC: {best_aic:.2f}\")\n",
    "    return best_model\n",
    "\n",
    "def train_knn(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train KNN model with hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]  # 1: manhattan, 2: euclidean\n",
    "    }\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search = GridSearchCV(\n",
    "        KNeighborsRegressor(),\n",
    "        param_grid,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best KNN parameters: {grid_search.best_params_}\")\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results storage\n",
    "results = {}\n",
    "\n",
    "# Train ARIMA\n",
    "print(\"Training ARIMA model...\")\n",
    "arima_model = train_arima(y_train)\n",
    "arima_pred = arima_model.forecast(steps=len(y_test))\n",
    "results['ARIMA'] = evaluate_model(y_test, arima_pred, \"ARIMA\")\n",
    "\n",
    "# Train KNN\n",
    "print(\"\\nTraining KNN model...\")\n",
    "knn_model = train_knn(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "results['KNN'] = evaluate_model(y_test, knn_pred, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates_test, y_test, label='Actual', color='blue')\n",
    "plt.plot(dates_test, arima_pred, label='ARIMA', color='red', linestyle='--')\n",
    "plt.plot(dates_test, knn_pred, label='KNN', color='green', linestyle='-.')\n",
    "plt.title('Actual vs Predicted Rainfall')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best model\n",
    "best_model_name = results_df['RMSE'].idxmin()\n",
    "print(f\"\\nBest model based on RMSE: {best_model_name}\")\n",
    "\n",
    "# Save best model\n",
    "if best_model_name == 'ARIMA':\n",
    "    arima_model.save(\"../models/saved_models/arima_model.pkl\")\n",
    "elif best_model_name == 'KNN':\n",
    "    import joblib\n",
    "    joblib.dump(knn_model, \"../models/saved_models/knn_model.pkl\")\n",
    "\n",
    "print(\"Best model saved to models/saved_models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement additional models (Random Forest, XGBoost, ANN)\n",
    "2. Add more sophisticated feature selection\n",
    "3. Implement ensemble methods\n",
    "4. Deploy best model in production pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
